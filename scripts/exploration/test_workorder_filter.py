#!/usr/bin/env python3
"""
Test complet : Simulation EXACTE du workflow GitHub Actions en 2 √©tapes
pour identifier pr√©cis√©ment o√π et pourquoi l'erreur FK se produit.
"""
import logging
import os
from supabase import create_client
from vysync.adapters.supabase_adapter import SupabaseAdapter, Client
from vysync.adapters.yuman_adapter import YumanAdapter
from vysync.diff import diff_fill_missing
from vysync.yuman_client import YumanClient
from vysync.vcom_client import VCOMAPIClient
from vysync.sync_tickets_workorders import (
    collect_vcom_tickets,
    collect_yuman_workorders,
    sync_tickets_to_db,
    sync_workorders_to_db,
    assign_tickets_to_active_workorders,
    create_workorders_for_priority_sites,
    close_tickets_of_closed_workorders
)

# Configuration du logging
logging.basicConfig(
    level=logging.INFO,
    format='%(levelname)s | %(message)s'
)
logger = logging.getLogger(__name__)

def test_github_workflow_complete():
    """
    Simule EXACTEMENT le workflow GitHub Actions en 2 √©tapes.
    """
    print("=" * 80)
    print("TEST COMPLET - SIMULATION WORKFLOW GITHUB ACTIONS")
    print("=" * 80)
    
    # Setup connexions
    sb_client = create_client(os.getenv("SUPABASE_URL"), os.getenv("SUPABASE_SERVICE_KEY"))
    sb = SupabaseAdapter()
    yc = YumanClient(os.getenv("YUMAN_TOKEN"))
    vc = VCOMAPIClient()
    
    print("\n" + "=" * 80)
    print("√âTAPE 1/2 : SYNC YUMAN ‚Üí SUPABASE MAPPINGS")
    print("=" * 80)
    
    print("\n‚Üí √âtat AVANT la synchro des mappings...")
    
    # Capturer l'√©tat initial
    initial_sites_mapping = sb_client.table("sites_mapping").select("yuman_site_id").execute()
    initial_valid_site_ids = {
        row["yuman_site_id"] 
        for row in initial_sites_mapping.data 
        if row["yuman_site_id"] is not None
    }
    logger.info(f"  Sites valides AVANT sync: {len(initial_valid_site_ids)}")
    
    # V√©rifier si 747491 existe avant
    has_747491_before = 747491 in initial_valid_site_ids
    logger.info(f"  Site 747491 pr√©sent AVANT: {has_747491_before}")
    
    print("\n‚Üí Ex√©cution de la synchro des mappings (comme GitHub Action)...")
    
    try:
        # 1) Snapshot Yuman (EXACTEMENT comme dans le workflow)
        y = YumanAdapter(sb)
        logger.info("[YUMAN‚ÜíDB] snapshot & patch fill-missing ‚Ä¶")
        y_clients_raw = list(yc.list_clients())
        y_sites = y.fetch_sites()
        
        logger.info(f"  Clients Yuman r√©cup√©r√©s: {len(y_clients_raw)}")
        logger.info(f"  Sites Yuman r√©cup√©r√©s: {len(y_sites)}")
        
        # V√©rifier si 747491 est dans les sites Yuman
        has_747491_in_yuman = 747491 in y_sites
        logger.info(f"  Site 747491 pr√©sent dans API Yuman: {has_747491_in_yuman}")
        
        # 2) Mappings existants en base
        db_clients = sb.fetch_clients()
        db_maps_sites = sb.fetch_sites_y()
        
        logger.info(f"  Clients en DB: {len(db_clients)}")
        logger.info(f"  Sites mappings en DB: {len(db_maps_sites)}")
        
        def to_client(row: dict) -> Client:
            return Client(
                yuman_client_id=row["id"],
                name=row.get("name"),
                code=row.get("code"),
                address=row.get("address") or row.get("billing_address")
            )
        
        y_clients = {r["id"]: to_client(r) for r in y_clients_raw}
        
        # 3) Diff ¬´ fill missing ¬ª
        patch_clients = diff_fill_missing(db_clients, y_clients)
        patch_maps_sites = diff_fill_missing(db_maps_sites, y_sites, fields=[
            "yuman_site_id", "code", "client_map_id", "name",
            "aldi_id", "aldi_store_id", "project_number_cp",
            "commission_date", "nominal_power"
        ])
        
        logger.info(
            "[YUMAN‚ÜíDB] Clients Œî +%d ~%d -%d",
            len(patch_clients.add), len(patch_clients.update), len(patch_clients.delete),
        )
        logger.info(
            "[YUMAN‚ÜíDB] SitesMapping Œî +%d ~%d -%d",
            len(patch_maps_sites.add), len(patch_maps_sites.update), len(patch_maps_sites.delete),
        )
        
        # V√©rifier si 747491 serait ajout√©/supprim√©/modifi√©
        if patch_maps_sites.add:
            added_747491 = any(s.yuman_site_id == 747491 for s in patch_maps_sites.add)
            if added_747491:
                logger.info("  ‚ö†Ô∏è  Site 747491 serait AJOUT√â par cette synchro")
        
        if patch_maps_sites.delete:
            deleted_747491 = any(s.yuman_site_id == 747491 for s in patch_maps_sites.delete)
            if deleted_747491:
                logger.warning("  ‚ö†Ô∏è  Site 747491 serait SUPPRIM√â par cette synchro")
        
        # 4) Application des patchs (MODE DRY - ne pas modifier r√©ellement)
        logger.info("\n  [DRY MODE] Simulation de l'application des patchs...")
        logger.info("  (en production, cela modifierait la DB)")
        
        # sb.apply_clients_mapping_patch(patch_clients)
        # sb.apply_sites_patch(patch_maps_sites)
        
        logger.info("  ‚úì √âTAPE 1 termin√©e (mode simulation)")
        
    except Exception as e:
        logger.error(f"  ‚úó ERREUR dans √âTAPE 1: {e}")
        import traceback
        traceback.print_exc()
        return
    
    print("\n‚Üí √âtat APR√àS la synchro des mappings...")
    
    # Recapturer l'√©tat (m√™me en dry mode, pour comparaison)
    after_sites_mapping = sb_client.table("sites_mapping").select("yuman_site_id").execute()
    after_valid_site_ids = {
        row["yuman_site_id"] 
        for row in after_sites_mapping.data 
        if row["yuman_site_id"] is not None
    }
    logger.info(f"  Sites valides APR√àS sync: {len(after_valid_site_ids)}")
    
    has_747491_after = 747491 in after_valid_site_ids
    logger.info(f"  Site 747491 pr√©sent APR√àS: {has_747491_after}")
    
    # Analyser les changements
    added_sites = after_valid_site_ids - initial_valid_site_ids
    removed_sites = initial_valid_site_ids - after_valid_site_ids
    
    if added_sites:
        logger.info(f"  Sites AJOUT√âS: {len(added_sites)}")
        if 747491 in added_sites:
            logger.info("    ‚Üí 747491 a √©t√© AJOUT√â")
    
    if removed_sites:
        logger.warning(f"  Sites SUPPRIM√âS: {len(removed_sites)}")
        if 747491 in removed_sites:
            logger.warning("    ‚Üí 747491 a √©t√© SUPPRIM√â")
    
    print("\n" + "=" * 80)
    print("√âTAPE 2/2 : SYNC TICKETS & WORKORDERS")
    print("=" * 80)
    
    print("\n‚Üí Collecte des donn√©es...")
    
    try:
        # 1. Collecte (EXACTEMENT comme dans main())
        tickets = collect_vcom_tickets(vc)
        workorders = collect_yuman_workorders(yc)
        
        logger.info(f"  Tickets VCOM r√©cup√©r√©s: {len(tickets)}")
        logger.info(f"  Workorders Yuman r√©cup√©r√©s: {len(workorders)}")
        
        # Analyser les workorders probl√©matiques
        wo_with_747491 = [w for w in workorders if w.get("site_id") == 747491]
        if wo_with_747491:
            logger.warning(f"\n  ‚ö†Ô∏è  {len(wo_with_747491)} workorder(s) avec site_id=747491:")
            for w in wo_with_747491:
                logger.warning(f"      - WO#{w.get('id')}: status={w.get('status')}")
        
        # V√©rifier si ces workorders existent d√©j√† en DB
        if wo_with_747491:
            existing_wo_ids = [w.get('id') for w in wo_with_747491]
            for wo_id in existing_wo_ids:
                check = sb_client.table("work_orders").select("*").eq("workorder_id", wo_id).execute()
                if check.data:
                    logger.warning(f"      WO#{wo_id} EXISTE D√âJ√Ä en DB avec site_id={check.data[0].get('site_id')}")
                else:
                    logger.info(f"      WO#{wo_id} N'existe PAS en DB")
        
        print("\n‚Üí Simulation de sync_workorders_to_db...")
        
        # R√©cup√©rer les site_ids valides (comme dans upsert_workorders)
        valid_site_ids_result = sb_client.table("sites_mapping").select("yuman_site_id").execute()
        valid_site_ids = {
            row["yuman_site_id"] 
            for row in valid_site_ids_result.data 
            if row["yuman_site_id"] is not None
        }
        
        logger.info(f"  Site_ids valides pour le filtrage: {len(valid_site_ids)}")
        logger.info(f"  747491 est valide: {747491 in valid_site_ids}")
        
        # Filtrage
        valid_orders = []
        ignored_orders = []
        
        for w in workorders:
            site_id = w.get("site_id")
            if site_id in valid_site_ids:
                valid_orders.append(w)
            else:
                ignored_orders.append(w)
        
        logger.info(f"  Workorders valides: {len(valid_orders)}")
        logger.info(f"  Workorders ignor√©s: {len(ignored_orders)}")
        
        if ignored_orders:
            logger.info(f"\n  Workorders ignor√©s d√©tails:")
            for w in ignored_orders:
                logger.info(f"    - WO#{w.get('id')}: site_id={w.get('site_id')}")
        
        # Construction des rows
        rows = [
            {
                "workorder_id": w["id"],
                "status": w.get("status"),
                "client_id": w.get("client_id"),
                "site_id": w.get("site_id"),
                "scheduled_date": w.get("date_planned"),
                "description": w.get("description"),
                "title": w.get("title"),
            }
            for w in valid_orders
        ]
        
        logger.info(f"  Rows √† upsert: {len(rows)}")
        
        # V√©rification finale de s√©curit√©
        invalid_rows = [r for r in rows if r["site_id"] not in valid_site_ids]
        if invalid_rows:
            logger.error(f"\n  ‚ùå PROBL√àME D√âTECT√â: {len(invalid_rows)} rows avec site_id INVALIDE!")
            for r in invalid_rows:
                logger.error(f"      - workorder_id={r['workorder_id']}, site_id={r['site_id']}")
            logger.error("  ‚Üí Ces rows causeraient la violation FK!")
        else:
            logger.info("  ‚úì Tous les rows ont un site_id valide")
        
        print("\n‚Üí Test des autres fonctions...")
        
        # Test create_workorders_for_priority_sites
        logger.info("\n  Test create_workorders_for_priority_sites...")
        
        active_sites = {
            w["site_id"] for w in workorders if w.get("status", "").lower() != "closed"
        }
        
        by_site = {}
        for t in tickets:
            if t.get("status") == "open" and t.get("priority") in ("high", "urgent"):
                row = (
                    sb_client.table("sites_mapping")
                    .select("yuman_site_id")
                    .eq("vcom_system_key", t.get("systemKey"))
                    .execute()
                ).data
                if row and row[0]["yuman_site_id"] is not None:
                    site_id = row[0]["yuman_site_id"]
                    by_site.setdefault(site_id, []).append(t)
        
        would_create_wo = []
        for site_id, ts in by_site.items():
            if site_id not in active_sites:
                would_create_wo.append((site_id, len(ts)))
                if site_id not in valid_site_ids:
                    logger.error(f"    ‚ùå Site {site_id} cr√©erait un WO MAIS n'est PAS valide!")
                    logger.error(f"       ‚Üí Cela causerait une violation FK lors de l'INSERT")
        
        if would_create_wo:
            logger.info(f"  {len(would_create_wo)} site(s) cr√©eraient un nouveau WO:")
            for site_id, count in would_create_wo:
                status = "‚úì" if site_id in valid_site_ids else "‚úó"
                logger.info(f"    {status} site_id={site_id} ({count} ticket(s))")
        
    except Exception as e:
        logger.error(f"  ‚úó ERREUR dans √âTAPE 2: {e}")
        import traceback
        traceback.print_exc()
        return
    
    print("\n" + "=" * 80)
    print("ANALYSE FINALE")
    print("=" * 80)
    
    print("\nüìä R√âSUM√â DES D√âCOUVERTES:")
    print(f"  ‚Ä¢ Site 747491 dans Yuman API: {has_747491_in_yuman if 'has_747491_in_yuman' in locals() else 'N/A'}")
    print(f"  ‚Ä¢ Site 747491 dans sites_mapping AVANT: {has_747491_before}")
    print(f"  ‚Ä¢ Site 747491 dans sites_mapping APR√àS: {has_747491_after}")
    print(f"  ‚Ä¢ Workorders avec site_id=747491: {len(wo_with_747491) if 'wo_with_747491' in locals() else 0}")
    print(f"  ‚Ä¢ Ces WO seraient ignor√©s par le filtrage: {len(wo_with_747491) > 0 and not has_747491_after}")
    
    print("\nüîç HYPOTH√àSES:")
    
    if wo_with_747491 and not has_747491_after:
        print("\n  ‚ö†Ô∏è  SC√âNARIO PROBABLE IDENTIFI√â:")
        print("  1. Des workorders Yuman r√©f√©rencent site_id=747491")
        print("  2. MAIS ce site n'existe PAS (ou plus) dans sites_mapping")
        print("  3. Le filtrage les ignore correctement")
        print("  4. CEPENDANT:")
        
        # V√©rifier si ces WO existent en DB
        for w in wo_with_747491:
            check = sb_client.table("work_orders").select("*").eq("workorder_id", w.get('id')).execute()
            if check.data:
                print(f"\n     ‚ùå PROBL√àME: WO#{w.get('id')} existe D√âJ√Ä en DB!")
                print(f"        ‚Ä¢ Actuellement en DB avec site_id={check.data[0].get('site_id')}")
                print(f"        ‚Ä¢ L'upsert va essayer de l'UPDATE")
                print(f"        ‚Ä¢ Mais site_id={check.data[0].get('site_id')} est invalide")
                print(f"        ‚Üí VIOLATION FK lors de l'UPDATE!")
                print("\n     üí° SOLUTION:")
                print("        Supprimer ce workorder de la DB ou corriger son site_id")
    
    if not has_747491_in_yuman and has_747491_before and not has_747491_after:
        print("\n  ‚ö†Ô∏è  Site 747491 a √©t√© SUPPRIM√â de sites_mapping")
        print("     (probablement via le diff_fill_missing)")
        print("     Mais des workorders le r√©f√©rencent encore")
    
    print("\n" + "=" * 80)

if __name__ == "__main__":
    test_github_workflow_complete()